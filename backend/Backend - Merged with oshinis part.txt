from flask import Flask, request, jsonify
import tensorflow as tf
import numpy as np
import cv2
import os
import json
import requests
import openmeteo_requests
import requests_cache
from retry_requests import retry
from werkzeug.utils import secure_filename
from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50
from tensorflow.keras.layers import GlobalAveragePooling2D
from tensorflow.keras.models import Model
from flask_cors import CORS
import traceback
import logging
from datetime import datetime

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
import pandas as pd

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# Configuration
UPLOAD_FOLDER = "uploads"
ALLOWED_EXTENSIONS = {"png", "jpg", "jpeg"}

app.config["UPLOAD_FOLDER"] = UPLOAD_FOLDER
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Define confidence thresholds
CONFIDENCE_THRESHOLDS = {
    "plant": 0.70,      # 70% confidence threshold for plant identification
    "deficiency": 0.65, # 65% confidence threshold for deficiency detection
    "severity": 0.60    # 60% confidence threshold for severity assessment
}

def allowed_file(filename):
    """Check if the file extension is allowed."""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS
def preprocess_image(image_path, target_size=(224, 224)):
    """Preprocess image for model input."""
    try:
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Failed to load image at {image_path}")

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, target_size)
        image = np.array(image, dtype=np.float32)
        image = np.expand_dims(image, axis=0)
        image = preprocess_input(image)
        return image
    except Exception as e:
        logger.error(f"Error preprocessing image: {str(e)}")
        logger.error(traceback.format_exc())
        raise

def get_deficiency_model(plant_type):
    """Get appropriate deficiency model for plant type."""
    try:
        plant_type = plant_type.title()
        if plant_type in DEFICIENCY_CLASSES:
            if plant_type == "Rice":
                return rice_model, DEFICIENCY_CLASSES[plant_type]
            elif plant_type == "Coffee":
                return coffee_model, DEFICIENCY_CLASSES[plant_type]
            elif plant_type == "Banana":
                return banana_model, DEFICIENCY_CLASSES[plant_type]
        raise ValueError(f"No deficiency model available for plant type: {plant_type}")
    except Exception as e:
        logger.error(f"Error getting deficiency model: {str(e)}")
        logger.error(traceback.format_exc())
        raise

# Load domain knowledge
with open('domain_knowledge.json', 'r') as f:
    DOMAIN_KNOWLEDGE = json.load(f)

# API configurations
IPSTACK_API_KEY = "2db412ca1de0d3257e022db62fc9ee38"
IPSTACK_URL = f"http://api.ipstack.com/check?access_key={IPSTACK_API_KEY}"

# Setup weather API
cache_session = requests_cache.CachedSession('.cache', expire_after=3600)
retry_session = retry(cache_session, retries=5, backoff_factor=0.2)
openmeteo = openmeteo_requests.Client(session=retry_session)

# Model Paths
PLANT_IDENTIFIER_MODEL = "plant_identification_full_model.h5"
RICE_MODEL_PATH = "rice_full_model.h5"
COFFEE_MODEL_PATH = "coffee_full_model.h5"
BANANA_MODEL_PATH = "banana_full_model.h5"
SEVERITY_MODEL_PATH = "FINALMODELforSeverity.h5"

# Load all models with error handling
try:
    logger.info("Loading models...")
    plant_identifier = tf.keras.models.load_model(PLANT_IDENTIFIER_MODEL)
    rice_model = tf.keras.models.load_model(RICE_MODEL_PATH)
    coffee_model = tf.keras.models.load_model(COFFEE_MODEL_PATH)
    banana_model = tf.keras.models.load_model(BANANA_MODEL_PATH)
    severity_model = tf.keras.models.load_model(SEVERITY_MODEL_PATH)

    logger.info(f"Plant identifier output shape: {plant_identifier.output_shape}")
    num_classes = plant_identifier.output_shape[-1]
    logger.info(f"Number of classes in plant identifier model: {num_classes}")
    logger.info("All models loaded successfully")
except Exception as e:
    logger.error(f"Error loading models: {str(e)}")
    logger.error(traceback.format_exc())
    raise

# Set up ResNet50 feature extractor for severity model
try:
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    feature_extractor = Model(inputs=base_model.input, outputs=x)
    logger.info("Feature extractor set up successfully")
except Exception as e:
    logger.error(f"Error setting up feature extractor: {str(e)}")
    logger.error(traceback.format_exc())
    raise

# Plant classes and deficiency mappings
PLANT_CLASSES = ["Banana", "Coffee", "Rice"]

DEFICIENCY_CLASSES = {
    "Rice": ["Nitrogen(N)", "Phosphorus(P)", "Potassium(K)"],
    "Coffee": ["iron-Fe", "magnesium-Mg", "potasium-K"],
    "Banana": ["iron", "magnesium", "potassium"]
}

SEVERITY_CLASSES = ["Mild", "Moderate", "Severe"]

# Helper functions for location and weather
def get_user_location():
    try:
        response = requests.get(IPSTACK_URL)
        data = response.json()
        lat = data.get('latitude')
        lon = data.get('longitude')
        city = data.get('city', 'Unknown')
        if lat is None or lon is None:
            raise ValueError("Invalid location data returned from IP Stack.")
        return lat, lon, city
    except Exception as e:
        logger.error(f"Error fetching location: {e}")
        return None, None, "Unknown"

def get_weather_data(lat, lon):
    try:
        url = "https://api.open-meteo.com/v1/forecast"
        params = {
            "latitude": lat,
            "longitude": lon,
            "current": ["temperature_2m", "relative_humidity_2m"]
        }
        responses = openmeteo.weather_api(url, params=params)
        response = responses[0]
        current = response.Current()
        temperature = current.Variables(0).Value()
        humidity = current.Variables(1).Value()
        return humidity, temperature
    except Exception as e:
        logger.error(f"Error fetching weather data: {e}")
        return None, None


# Additional helper functions for main backend
def check_environmental_conditions(plant_type, temperature, humidity):
    plant_conditions = DOMAIN_KNOWLEDGE["plant_conditions"].get(plant_type, {})
    if not plant_conditions:
        return "Environmental conditions data not available for this plant type"

    temp_range = plant_conditions.get("temp_range", [])
    humidity_range = plant_conditions.get("humidity_range", [])

    if temp_range and humidity_range:
        temp_ok = temp_range[0] <= temperature <= temp_range[1]
        humidity_ok = humidity_range[0] <= humidity <= humidity_range[1]

        if temp_ok and humidity_ok:
            return f"✅ Optimal: Temperature ({temperature}°C) and Humidity ({humidity}%) are within ideal ranges"
        else:
            return f"⚠️ Suboptimal: Ideal ranges are {temp_range[0]}-{temp_range[1]}°C and {humidity_range[0]}-{humidity_range[1]}% humidity"
    return "Could not determine environmental suitability"


def check_soil_suitability(plant_type, soil_type):
    soil_preferences = DOMAIN_KNOWLEDGE["soil_preferences"].get(plant_type, {})
    if not soil_preferences:
        return "Soil preference data not available for this plant type"

    suitable_soils = soil_preferences.get("suitable_soils", [])
    if soil_type in suitable_soils:
        return f"✅ Suitable: {soil_type} soil is ideal for {plant_type}"
    else:
        return f"⚠️ Not Ideal: {plant_type} prefers {', '.join(suitable_soils)} soil"


DEFICIENCY_NAME_MAPPING = {
    # Rice format
    "Nitrogen(N)": "Nitrogen",
    "Phosphorus(P)": "Phosphorus",
    "Potassium(K)": "Potassium",

    # Coffee format
    "iron-Fe": "Iron",
    "magnesium-Mg": "Magnesium",
    "potasium-K": "Potassium",  # Note: handles the misspelling in your classes

    # Banana format
    "iron": "Iron",
    "magnesium": "Magnesium",
    "potassium": "Potassium",

    # Additional variations
    "nitrogen": "Nitrogen",
    "phosphorus": "Phosphorus",
    "n": "Nitrogen",
    "p": "Phosphorus",
    "k": "Potassium",
    "fe": "Iron",
    "mg": "Magnesium"
}


def get_fertilizer_recommendation(deficiency_type, severity_level):
    """Get fertilizer recommendation based on deficiency type and severity."""
    try:
        if deficiency_type == "Unknown":
            return "Cannot provide recommendation without valid deficiency type"

        recommendations = DOMAIN_KNOWLEDGE["fertilizer_recommendations"]

        # Debug logging
        logger.info(f"Getting recommendation for: {deficiency_type} (Severity: {severity_level})")

        # Clean the input
        cleaned_type = deficiency_type.strip()

        # First try direct mapping
        if cleaned_type in DEFICIENCY_NAME_MAPPING:
            standard_name = DEFICIENCY_NAME_MAPPING[cleaned_type]
        else:
            # Try different variations
            cleaned_lower = cleaned_type.lower()

            # Remove parentheses and hyphens
            base_name = cleaned_lower
            if '(' in base_name:
                base_name = base_name.split('(')[0].strip()
            if '-' in base_name:
                base_name = base_name.split('-')[0].strip()

            # Try to find a match
            if base_name in DEFICIENCY_NAME_MAPPING:
                standard_name = DEFICIENCY_NAME_MAPPING[base_name]
            else:
                # Try partial matching
                matches = [value for key, value in DEFICIENCY_NAME_MAPPING.items()
                           if base_name in key.lower()]
                standard_name = matches[0] if matches else None

        logger.info(f"Standardized name: {standard_name}")

        if standard_name and standard_name in recommendations:
            if severity_level in recommendations[standard_name]:
                recommendation = recommendations[standard_name][severity_level]
                logger.info(f"Found recommendation: {recommendation}")
                return recommendation
            else:
                logger.warning(f"No recommendation found for severity level: {severity_level}")
                return f"No specific {severity_level} severity recommendation available for {standard_name} deficiency"

        logger.warning(f"No recommendation found for deficiency type: {deficiency_type}")
        return f"No recommendation found for {deficiency_type} deficiency"

    except Exception as e:
        logger.error(f"Error in get_fertilizer_recommendation: {str(e)}")
        logger.error(traceback.format_exc())
        return "Error getting fertilizer recommendation"

@app.route("/predict", methods=["POST"])
def predict():
    try:
        if "file" not in request.files:
            return jsonify({"error": "No file uploaded"}), 400

        file = request.files["file"]
        soil_type = request.form.get('soil_type', 'Unknown')  # Get soil type if provided

        if file.filename == "":
            return jsonify({"error": "No selected file"}), 400

        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            file_path = os.path.join(app.config["UPLOAD_FOLDER"], filename)
            file.save(file_path)
            logger.info(f"File saved successfully at {file_path}")

            try:
                # Get location and weather data
                lat, lon, city = get_user_location()
                humidity, temperature = get_weather_data(lat, lon) if lat and lon else (None, None)

                # Step 1: Plant Identification with validation
                logger.info("Starting plant identification")
                plant_image = preprocess_image(file_path)
                plant_predictions = plant_identifier.predict(plant_image)

                plant_class_idx = np.argmax(plant_predictions)
                plant_confidence = float(plant_predictions[0][plant_class_idx])

                # Validate plant confidence
                if plant_confidence < CONFIDENCE_THRESHOLDS["plant"]:
                    return jsonify({
                        "plant": {
                            "type": "Unknown",
                            "confidence": plant_confidence,
                            "message": "Unable to identify plant type with sufficient confidence"
                        },
                        "deficiency": {
                            "type": "Unknown",
                            "confidence": 0.0
                        },
                        "severity": {
                            "level": "Unknown",
                            "confidence": 0.0
                        }
                    })

                plant_type = PLANT_CLASSES[plant_class_idx]
                logger.info(f"Plant identified as: {plant_type} with confidence: {plant_confidence}")

                # Step 2: Deficiency Analysis
                deficiency_model, deficiency_labels = get_deficiency_model(plant_type)
                deficiency_predictions = deficiency_model.predict(plant_image)
                deficiency_class_idx = np.argmax(deficiency_predictions)
                deficiency_confidence = float(deficiency_predictions[0][deficiency_class_idx])

                # Validate deficiency confidence
                if deficiency_confidence < CONFIDENCE_THRESHOLDS["deficiency"]:
                    deficiency_type = "Unknown"
                    deficiency_message = "Unable to identify deficiency with sufficient confidence"
                else:
                    deficiency_type = deficiency_labels[deficiency_class_idx]
                    deficiency_message = None

                # Step 3: Severity Analysis
                features = feature_extractor.predict(plant_image)
                severity_predictions = severity_model.predict(features)
                severity_class_idx = np.argmax(severity_predictions)
                severity_confidence = float(severity_predictions[0][severity_class_idx])

                # Validate severity confidence
                if severity_confidence < CONFIDENCE_THRESHOLDS["severity"]:
                    severity_level = "Unknown"
                    severity_message = "Unable to determine severity with sufficient confidence"
                else:
                    severity_level = SEVERITY_CLASSES[severity_class_idx]
                    severity_message = None

                # Get environmental analysis
                env_status = check_environmental_conditions(plant_type, temperature,
                                                            humidity) if temperature and humidity else "Weather data unavailable"
                soil_status = check_soil_suitability(plant_type,
                                                     soil_type) if soil_type != "Unknown" else "Soil type not provided"

                # Get fertilizer recommendation
                fertilizer_rec = get_fertilizer_recommendation(deficiency_type,
                                                               severity_level) if deficiency_type != "Unknown" else "Cannot provide recommendation without valid deficiency type"

                # Clean up
                os.remove(file_path)
                logger.info("Temporary file removed")

                # Prepare response
                response = {
                    "plant": {
                        "type": plant_type,
                        "confidence": plant_confidence
                    },
                    "deficiency": {
                        "type": deficiency_type,
                        "confidence": deficiency_confidence,
                        "message": deficiency_message
                    },
                    "severity": {
                        "level": severity_level,
                        "confidence": severity_confidence,
                        "message": severity_message
                    },
                    "environmental_analysis": {
                        "location": city,
                        "temperature": temperature,
                        "humidity": humidity,
                        "status": env_status
                    },
                    "soil_analysis": {
                        "soil_type": soil_type,
                        "status": soil_status
                    },
                    "recommendation": {
                        "treatment": fertilizer_rec,
                        "guidelines": DOMAIN_KNOWLEDGE["fertilizer_application_guidelines"]
                    },
                    "timestamp": datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
                }

                return jsonify(response)

            except Exception as e:
                logger.error(f"Error during prediction: {str(e)}")
                logger.error(traceback.format_exc())
                if os.path.exists(file_path):
                    os.remove(file_path)
                return jsonify({"error": str(e)}), 500

        return jsonify({"error": "Invalid file type"}), 400

    except Exception as e:
        logger.error(f"Unexpected error: {str(e)}")
        logger.error(traceback.format_exc())
        return jsonify({"error": "An unexpected error occurred"}), 500


# Add these new routes to your existing app.py
try:
    logger.info("Loading crop recommendation model...")
    # Load plant dataset
    crop_data = pd.read_csv("crops.csv")

    # Prepare features and target
    X = crop_data[['temperature', 'humidity', 'ph', 'rainfall']]
    y = crop_data['label']

    # Initialize encoders and scalers
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Split and train model
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42
    )

    rf_model = RandomForestClassifier(
        n_estimators=300,
        max_depth=10,
        max_features='sqrt',
        min_samples_leaf=1,
        min_samples_split=2,
        random_state=42
    )
    rf_model.fit(X_train, y_train)
    logger.info("Crop recommendation model loaded successfully")
except Exception as e:
    logger.error(f"Error loading crop recommendation model: {str(e)}")
    logger.error(traceback.format_exc())
    raise

def get_crop_weather_data(location):
    try:
        latitude, longitude = get_coordinates(location)
        if latitude is None or longitude is None:
            return None, None, None

        url = "https://archive-api.open-meteo.com/v1/archive"
        params = {
            "latitude": latitude,
            "longitude": longitude,
            "start_date": "2024-01-01",
            "end_date": "2024-12-31",
            "hourly": "relative_humidity_2m",
            "daily": ["temperature_2m_mean", "rain_sum"]
        }
        responses = openmeteo.weather_api(url, params=params)
        response = responses[0]

        daily = response.Daily()
        temperature = daily.Variables(0).ValuesAsNumpy().mean()
        humidity = response.Hourly().Variables(0).ValuesAsNumpy().mean()
        rainfall = daily.Variables(1).ValuesAsNumpy().sum()

        return temperature, humidity, rainfall
    except Exception as e:
        logger.error(f"Error getting crop weather data: {str(e)}")
        return None, None, None

def get_coordinates(location):
    """Get coordinates from location name using Geoapify"""
    url = f"https://api.geoapify.com/v1/geocode/autocomplete?text={location}&apiKey=f4f2dd36b76a42d690a9ae4dcf1b8703"
    headers = {"Accept": "application/json"}
    try:
        resp = requests.get(url, headers=headers)
        if resp.status_code == 200:
            data = resp.json()
            if "features" in data and data["features"]:
                lat = data["features"][0]["geometry"]["coordinates"][1]
                lon = data["features"][0]["geometry"]["coordinates"][0]
                return lat, lon
            else:
                raise ValueError("Location not found or invalid response.")
        else:
            raise ValueError(f"API request failed with status code {resp.status_code}")
    except requests.RequestException as e:
        raise ValueError(f"Error fetching coordinates: {e}")

def get_soil_ph(location):
    """Get soil pH from Excel file"""
    try:
        soil_file_path = "SP.xlsx"
        df = pd.read_excel(soil_file_path, engine='openpyxl')  # Specify the engine
        location_row = df[df['location'] == location]
        if not location_row.empty:
            return location_row['ph'].values[0]
        return None
    except Exception as e:
        logger.error(f"Error getting soil pH: {str(e)}")
        return None

def predict_top_crops(location, top_n=20):
    try:
        ph = get_soil_ph(location)
        if ph is None:
            return {"error": f"pH data not found for {location}."}

        temperature, humidity, rainfall = get_crop_weather_data(location)
        if temperature is None or humidity is None or rainfall is None:
            return {"error": f"Weather data not found for {location}."}

        # Create input features
        input_features = np.array([[temperature, humidity, ph, rainfall]])
        input_features_scaled = scaler.transform(input_features)

        # Get predictions and probabilities
        probabilities = rf_model.predict_proba(input_features_scaled)[0]
        top_indices = np.argsort(probabilities)[-top_n:][::-1]
        top_crops = [label_encoder.classes_[i] for i in top_indices if i < len(label_encoder.classes_)]

        return {
            "plants": [{"name": crop} for crop in top_crops],
            "metadata": {
                "temperature": float(temperature),
                "humidity": float(humidity),
                "rainfall": float(rainfall),
                "ph": float(ph)
            }
        }
    except Exception as e:
        logger.error(f"Error in predict_top_crops: {str(e)}")
        return {"error": str(e)}

@app.route('/crop-recommendation')
def crop_recommendation_page():
    return render_template('crop_recommendation.html')

@app.route('/get-locations', methods=['GET'])
def get_locations():
    try:
        soil_file_path = "SP.xlsx"
        df = pd.read_excel(soil_file_path, engine='openpyxl')  # Specify the engine
        locations = df['location'].unique().tolist()
        return jsonify({"locations": locations})
    except Exception as e:
        logger.error(f"Error getting locations: {str(e)}")
        return jsonify({"error": str(e), "locations": []}), 500  # Return empty list if error

@app.route('/predict-crop', methods=['POST'])
def predict_crop():
    try:
        location = request.form.get('location')
        if not location:
            return jsonify({"error": "Location is required."}), 400

        result = predict_top_crops(location)
        if isinstance(result, dict) and 'error' in result:
            return jsonify(result), 404

        return jsonify({
            "plants": result["plants"],
            "timestamp": datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),
            "analyzed_by": "Muh-Ayyub"
        })

    except Exception as e:
        logger.error(f"Error in predict_crop: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/getExcelData', methods=['GET'])
def get_excel_data():
    try:
        df = pd.read_excel("location_wise_plants.xlsx", engine='openpyxl')  # Specify the engine
        excel_data = {}
        current_location = None

        for index, row in df.iterrows():
            location = row["location"]
            plant = row["plants"]

            if pd.notna(location):
                current_location = location.lower()
                excel_data[current_location] = []

            if pd.notna(plant):
                excel_data[current_location].append(plant.lower())

        return jsonify(excel_data)

    except Exception as e:
        logger.error(f"Error getting Excel data: {str(e)}")
        return jsonify({"error": str(e), "data": {}}), 500  # Return empty object if error


if __name__ == "__main__":
    app.run(debug=True)